cpu-bind=MASK - dlcgpu08, task  0  0 [38829]: mask 0x4000000040000000 set
cpu-bind=MASK - dlcgpu08, task  0  0 [38846]: mask 0x4000000040000000 set
/home/mutakeks/cv_env/lib/python3.10/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
W0712 16:53:59.794000 38846 cv_env/lib/python3.10/site-packages/torch/distributed/run.py:793] 
W0712 16:53:59.794000 38846 cv_env/lib/python3.10/site-packages/torch/distributed/run.py:793] *****************************************
W0712 16:53:59.794000 38846 cv_env/lib/python3.10/site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0712 16:53:59.794000 38846 cv_env/lib/python3.10/site-packages/torch/distributed/run.py:793] *****************************************
[rank: 0] Seed set to 42
[rank: 1] Seed set to 42
/home/mutakeks/cv_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/mutakeks/cv_env/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/mutakeks/cv_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/mutakeks/cv_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/mutakeks/cv_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/mutakeks/cv_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/mutakeks/final_titok/MastersProject_TiTok/taming/modules/losses/lpips.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.load_state_dict(torch.load(ckpt, map_location=torch.device("cpu")), strict=False)
/home/mutakeks/final_titok/MastersProject_TiTok/taming/modules/losses/lpips.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.load_state_dict(torch.load(ckpt, map_location=torch.device("cpu")), strict=False)
/home/mutakeks/maskgit_1d/maskgit_img/models/maskgit.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(tokenizer_folder, checkpoint_folder), map_location="cpu")["state_dict"]
/home/mutakeks/maskgit_1d/maskgit_img/models/maskgit.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(os.path.join(tokenizer_folder, checkpoint_folder), map_location="cpu")["state_dict"]
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
2025-07-12 16:54:59.022338: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-12 16:54:59.923213: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-07-12 16:55:02.382966: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2025-07-12 16:55:02.383993: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2025-07-12 16:55:02.384195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Restoring states from the checkpoint path at /work/dlclarge2/mutakeks-titok/maskgit_1d_titok64_150/checkpoints/last.ckpt
/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:362: The dirpath has changed from '/work/dlclarge2/mutakeks-titok/maskgit_1d_titok64_150/checkpoints' to '/work/dlclarge2/mutakeks-titok/maskgit_1d_titok64_150/checkpoints/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:362: The dirpath has changed from '/work/dlclarge2/mutakeks-titok/maskgit_1d_titok64_150/checkpoints' to '/work/dlclarge2/mutakeks-titok/maskgit_1d_titok64_150/checkpoints/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name      | Type                               | Params | Mode 
-------------------------------------------------------------------------
0 | ae        | VQModel2WithEntropyDINOLossMAEinit | 148 M  | eval 
1 | vit       | MaskTransformer                    | 118 M  | train
2 | criterion | CrossEntropyLoss                   | 0      | train
3 | scheduler | UnconditionalMaskGITScheduler      | 0      | train
-------------------------------------------------------------------------
252 M     Trainable params
14.7 M    Non-trainable params
267 M     Total params
1,069.043 Total estimated model params size (MB)
260       Modules in train mode
412       Modules in eval mode
Restored all states from the checkpoint at /work/dlclarge2/mutakeks-titok/maskgit_1d_titok64_150/checkpoints/last.ckpt
/home/mutakeks/cv_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/home/mutakeks/cv_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:221: You're resuming from a checkpoint that ended before the epoch ended and your dataloader is not resumable. This can cause unreliable results if further training is done. Consider using an end-of-epoch checkpoint or make your dataloader resumable by implementing the `state_dict` / `load_state_dict` interface.
/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train/ce_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('train/ce_loss_window', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:384: `ModelCheckpoint(monitor='val/ce_loss')` could not find the monitored key in the returned metrics: ['train/ce_loss', 'train/ce_loss_step', 'train/ce_loss_window', 'train/ce_loss_window_step', 'lr-AdamW', 'train/ce_loss_epoch', 'train/ce_loss_window_epoch', 'epoch', 'step']. HINT: Did you call `log('val/ce_loss', value)` in the `LightningModule`?
`Trainer.fit` stopped: `max_epochs=30` reached.
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/mutakeks/maskgit_1d/maskgit_img/main_pl.py", line 525, in <module>
[rank0]:     trainer.test(model, data)
[rank0]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 749, in test
[rank0]:     return call._call_and_handle_interrupt(
[rank0]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 789, in _test_impl
[rank0]:     results = self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 932, in _run
[rank0]:     _verify_loop_configurations(self)
[rank0]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py", line 41, in _verify_loop_configurations
[rank0]:     __verify_eval_loop_configuration(model, "test")
[rank0]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py", line 106, in __verify_eval_loop_configuration
[rank0]:     raise MisconfigurationException(f"No `{step_name}()` method defined to run `Trainer.{trainer_method}`.")
[rank0]: lightning_fabric.utilities.exceptions.MisconfigurationException: No `test_step()` method defined to run `Trainer.test`.
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/mutakeks/maskgit_1d/maskgit_img/main_pl.py", line 525, in <module>
[rank1]:     trainer.test(model, data)
[rank1]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 749, in test
[rank1]:     return call._call_and_handle_interrupt(
[rank1]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank1]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 789, in _test_impl
[rank1]:     results = self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 932, in _run
[rank1]:     _verify_loop_configurations(self)
[rank1]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py", line 41, in _verify_loop_configurations
[rank1]:     __verify_eval_loop_configuration(model, "test")
[rank1]:   File "/home/mutakeks/cv_env/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py", line 106, in __verify_eval_loop_configuration
[rank1]:     raise MisconfigurationException(f"No `{step_name}()` method defined to run `Trainer.{trainer_method}`.")
[rank1]: lightning_fabric.utilities.exceptions.MisconfigurationException: No `test_step()` method defined to run `Trainer.test`.
W0713 14:26:16.325000 38846 cv_env/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 38850 closing signal SIGTERM
E0713 14:26:16.592000 38846 cv_env/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 1 (pid: 38851) of binary: /home/mutakeks/cv_env/bin/python
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/mutakeks/cv_env/lib/python3.10/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/mutakeks/cv_env/lib/python3.10/site-packages/typing_extensions.py", line 2853, in wrapper
    return arg(*args, **kwargs)
  File "/home/mutakeks/cv_env/lib/python3.10/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/mutakeks/cv_env/lib/python3.10/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/mutakeks/cv_env/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/mutakeks/cv_env/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/mutakeks/cv_env/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_pl.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-13_14:26:16
  host      : dlcgpu08.rz.ki.privat
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 38851)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: dlcgpu08: task 0: Exited with exit code 1
